{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d05994",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Khmer to Romanization Test\n",
    "# -----------------------------\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import load_model, Model\n",
    "from tensorflow.keras.layers import Input\n",
    "\n",
    "# -----------------------------\n",
    "# 1. Configuration\n",
    "# -----------------------------\n",
    "MODEL_PATH = \"s2s.h5\"         # Path to your trained model\n",
    "DATA_INPUT = \"csv/data_kh.csv\"\n",
    "DATA_TARGET = \"csv/data_rom.csv\"\n",
    "\n",
    "# -----------------------------\n",
    "# 2. Load model and vocab\n",
    "# -----------------------------\n",
    "print(\"Loading model...\")\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "print(\"Reading CSV data...\")\n",
    "input_texts = pd.read_csv(DATA_INPUT, header=None)[0].astype(str).tolist()\n",
    "target_texts = pd.read_csv(DATA_TARGET, header=None)[0].astype(str).tolist()\n",
    "target_texts = [\"\\t\" + t.strip() + \"\\n\" for t in target_texts]\n",
    "\n",
    "input_characters = sorted(list(set(\"\".join(input_texts))))\n",
    "target_characters = sorted(list(set(\"\".join(target_texts))))\n",
    "\n",
    "num_encoder_tokens = len(input_characters)\n",
    "num_decoder_tokens = len(target_characters)\n",
    "max_encoder_seq_length = max(len(txt) for txt in input_texts)\n",
    "max_decoder_seq_length = max(len(txt) for txt in target_texts)\n",
    "\n",
    "input_token_index = {char: i for i, char in enumerate(input_characters)}\n",
    "target_token_index = {char: i for i, char in enumerate(target_characters)}\n",
    "reverse_target_char_index = {i: char for char, i in target_token_index.items()}\n",
    "\n",
    "print(f\"KH vocab size: {num_encoder_tokens}\")\n",
    "print(f\"ROM vocab size: {num_decoder_tokens}\")\n",
    "\n",
    "# -----------------------------\n",
    "# 3. Rebuild inference models\n",
    "# -----------------------------\n",
    "# Encoder\n",
    "encoder_inputs = model.input[0]\n",
    "encoder_outputs, state_h_enc, state_c_enc = model.layers[2].output\n",
    "encoder_states = [state_h_enc, state_c_enc]\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "# Decoder\n",
    "decoder_inputs = model.input[1]\n",
    "decoder_lstm = model.layers[3]\n",
    "decoder_dense = model.layers[4]\n",
    "\n",
    "decoder_state_input_h = Input(shape=(state_h_enc.shape[1],), name=\"decoder_input_h\")\n",
    "decoder_state_input_c = Input(shape=(state_c_enc.shape[1],), name=\"decoder_input_c\")\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs\n",
    ")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# 4. Helper functions\n",
    "# -----------------------------\n",
    "def encode_input_text(text):\n",
    "    x = np.zeros((1, max_encoder_seq_length, num_encoder_tokens), dtype=\"float32\")\n",
    "    for t, char in enumerate(text):\n",
    "        if char in input_token_index:\n",
    "            x[0, t, input_token_index[char]] = 1.0\n",
    "    return x\n",
    "\n",
    "def decode_sequence(input_seq):\n",
    "    states_value = encoder_model.predict(input_seq, verbose=0)\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    target_seq[0, 0, target_token_index[\"\\t\"]] = 1.0\n",
    "\n",
    "    decoded_sentence = \"\"\n",
    "    stop_condition = False\n",
    "\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict([target_seq] + states_value, verbose=0)\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        if sampled_char == \"\\n\" or len(decoded_sentence) > max_decoder_seq_length:\n",
    "            stop_condition = True\n",
    "\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.0\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence.strip()\n",
    "\n",
    "# -----------------------------\n",
    "# 5. Test with input\n",
    "# -----------------------------\n",
    "# Optional: create a dictionary of KH -> ROM from CSV for reference\n",
    "reference_dict = {kh.strip(): rom.strip() for kh, rom in zip(input_texts, target_texts)}\n",
    "\n",
    "print(\"\\n--- Khmer Romanization Test Ready ---\")\n",
    "\n",
    "# Example interactive testing\n",
    "while True:\n",
    "    kh_text = input(\"\\nEnter Khmer word (or 'q' to quit): \").strip()\n",
    "    if kh_text.lower() == \"q\":\n",
    "        break\n",
    "    if not kh_text:\n",
    "        continue\n",
    "\n",
    "    # Encode and predict\n",
    "    input_seq = encode_input_text(kh_text)\n",
    "    predicted_rom = decode_sequence(input_seq)\n",
    "\n",
    "    # Reference from CSV (if exists)\n",
    "    reference_rom = reference_dict.get(kh_text, \"N/A\")\n",
    "\n",
    "    print(f\"KH: {kh_text}, Roman (reference): {reference_rom}, Predicted: {predicted_rom}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875b04bc-9a40-48c4-a15a-4f4b2e9a529a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
